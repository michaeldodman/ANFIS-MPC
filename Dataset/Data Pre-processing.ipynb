{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all csv files in data folder, and save to separate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in Data folder: ['ID_1_TRIAL_1.csv', 'ID_1_TRIAL_2.csv', 'ID_2_TRIAL_1.csv', 'ID_3_TRIAL_1.csv', 'ID_4_TRIAL_1.csv', 'ID_5_TRAIL_1.csv', 'ID_5_TRAIL_2.csv', 'ID_6_TRIAL_1.csv', 'ID_7_TRAIL_1.csv', 'ID_8_TRAIL_1.csv', 'ID_8_TRIAL_2.csv', 'ID_9_TRAIL_1.csv', 'ID_9_TRIAL_2.csv']\n",
      "All .csv files in Data folder: ['ID_1_TRIAL_1.csv', 'ID_1_TRIAL_2.csv', 'ID_2_TRIAL_1.csv', 'ID_3_TRIAL_1.csv', 'ID_4_TRIAL_1.csv', 'ID_5_TRAIL_1.csv', 'ID_5_TRAIL_2.csv', 'ID_6_TRIAL_1.csv', 'ID_7_TRAIL_1.csv', 'ID_8_TRAIL_1.csv', 'ID_8_TRIAL_2.csv', 'ID_9_TRAIL_1.csv', 'ID_9_TRIAL_2.csv']\n"
     ]
    }
   ],
   "source": [
    "# list .xlsx files in Data folder\n",
    "path = r'Raw Data'\n",
    "files = os.listdir(path)\n",
    "print('All files in Data folder:', files)\n",
    "# Pick out '.xlsx' files\n",
    "files_csv = [f for f in files if f[-3:] == 'csv']\n",
    "print('All .csv files in Data folder:',files_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to interpolate between values - data observations should already be sorted in ascending time\n",
    "def interpolate(query, x, y):\n",
    "    new_array = np.interp(query, x, y)\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each .csv, remove unneccessary columns, feature engineering, time step standardisation, append to overall input and output dataframes for all .csv's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_1_TRIAL_1.csv\n",
      "ID_1_TRIAL_2.csv\n",
      "ID_2_TRIAL_1.csv\n",
      "ID_3_TRIAL_1.csv\n",
      "ID_4_TRIAL_1.csv\n",
      "ID_5_TRAIL_1.csv\n",
      "ID_5_TRAIL_2.csv\n",
      "ID_6_TRIAL_1.csv\n",
      "ID_7_TRAIL_1.csv\n",
      "ID_8_TRAIL_1.csv\n",
      "ID_8_TRIAL_2.csv\n",
      "ID_9_TRAIL_1.csv\n",
      "ID_9_TRIAL_2.csv\n"
     ]
    }
   ],
   "source": [
    "# all .csv files in folder 'Data' are loaded in, the time step is standardised through interpolation of all columns, and then all saved to\n",
    "# the large matrices 'input' and 'output' ready for further processing.\n",
    "input = pd.DataFrame()\n",
    "output = pd.DataFrame()\n",
    "\n",
    "for f in files_csv:\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    data = pd.read_csv(r'Data/' + f,index_col=False)\n",
    "    print(f)\n",
    "    \n",
    "    # remove spaces at the beginning of column names\n",
    "    data.columns = data.columns.str.lstrip()\n",
    "    \n",
    "    # remove unneccessary columns - Position y, Velocity y, Rotation x, Rotation z\n",
    "\n",
    "    data.drop(columns=['Position y','Velocity y', 'Rotation x','Rotation z','Angular Velocity x','Angular Velocity z'])\n",
    "\n",
    "    # convert Rotation y from quarternion to radians\n",
    "\n",
    "    data['Rotation y'] = pd.Series(data['Rotation y']).transform(lambda x: 2*math.asin(x)*(180/math.pi))\n",
    "\n",
    "    idx = np.argwhere((data['Rotation y'].to_numpy()<-179) | (data['Rotation y'].to_numpy()>179))\n",
    "    if idx.any():\n",
    "        idx = min(idx)-1\n",
    "        # remove all rows PAST idx\n",
    "        data.drop(data.tail(len(data['Rotation y'])-idx[0]).index,inplace=True)\n",
    "\n",
    "    #data = data.drop(columns = ['Position y','Velocity y','Rotation x','Rotation z'])\n",
    "\n",
    "    # feature engineering - calculate alphaX, alphaZ, omega, omega_dot\n",
    "    time_diff = [j-i for i, j in zip(data['Time'].iloc[:-1][:-1], data['Time'].iloc[:-1][1:])]\n",
    "\n",
    "    alphax = [(j - i) / (k - l) for j, i, k, l in zip(data['Velocity x'][:-1], data['Velocity x'].iloc[1:], data['Time'][:-1], data['Time'].iloc[1:])]\n",
    "    alphaz = [(j - i) / (k - l) for j, i, k, l in zip(data['Velocity z'][:-1], data['Velocity z'].iloc[1:], data['Time'][:-1], data['Time'].iloc[1:])]\n",
    "    omega_dot = [(j - i) / (k - l) for j, i, k, l in zip(data['Angular Velocity y'][:-1], data['Angular Velocity y'].iloc[1:], data['Time'][:-1], data['Time'].iloc[1:])]\n",
    "    \n",
    "\n",
    "    # get rid of last 2 entries of original values and last entry of first order engineered features\n",
    "    data.drop(data.tail(2).index,inplace=True) \n",
    "    new_features = pd.DataFrame({'Acceleration x': alphax, 'Acceleration z': alphaz, 'Angular Acceleration y': omega_dot},columns = ['Acceleration x','Acceleration z', 'Angular Acceleration y'])\n",
    "    new_features.drop(new_features.tail(1).index,inplace=True) \n",
    "\n",
    "    # combine all data into 'data' dataframe\n",
    "    data[new_features.columns] = new_features\n",
    "    #data['Omega dot'] = omega_dot\n",
    "\n",
    "    # find max and min time so that a query list of time values can be generated\n",
    "    time_step = 0.02 # seconds\n",
    "    # check current min resolution\n",
    "    min_res = min(time_diff)\n",
    "    max_res = max(time_diff)\n",
    "    \n",
    "    # generate linearly spaced array of time steps starting at 0\n",
    "    count = 0\n",
    "    query = [0]\n",
    "    while query[count] + time_step < max(data['Time']):\n",
    "        count += 1\n",
    "        query.append(count*time_step)\n",
    "    \n",
    "    # interpolate for constant time step - assume linearity over a small time step\n",
    "    # query - query times, x - list of times from data, y - list of corresponding attribute values\n",
    "    # remove time column\n",
    "    Time = data['Time']\n",
    "    data = data.drop(columns=['Time'])\n",
    "\n",
    "    for col in data:\n",
    "        df[col] = interpolate(query,Time, data[col])\n",
    "    \n",
    "    # add query (time) column back into df\n",
    "    df.insert(loc = 0, column = 'Time', value=query)\n",
    "    \n",
    "    # create input and output matrices by removing last row of input and removing first row of output\n",
    "\n",
    "    input_local = df[:-1]\n",
    "    output_local = df.iloc[1: , :]\n",
    "\n",
    "    # append all values to the same input and output arrays\n",
    "\n",
    "    input = input.append(input_local)\n",
    "    output = output.append(output_local)\n",
    "\n",
    "# drop unneccessary output columns\n",
    "\n",
    "input = input.drop(columns=['Time'])\n",
    "output = output.drop(columns=['Time','Throttle','Brake','Steering'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.to_csv('complete_input.csv',index=False)\n",
    "output.to_csv('complete_output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the input data to values between 0 and 1\n",
    "# scaler = MinMaxScaler()\n",
    "# norm_input = scaler.fit_transform(input)\n",
    "# norm_input = pd.DataFrame(norm_input, index = input.index, columns = input.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_input.to_csv('complete_input_normalised.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eea02655494ccfca9b943908b44a342bce2b5b6ec71a404df79d1eaeac6a6912"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
